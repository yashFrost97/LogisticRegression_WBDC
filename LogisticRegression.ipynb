{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#capturing the dataset here\n",
    "dataset = pd.DataFrame(pd.read_csv('wdbc.dataset', header = None))\n",
    "dataset = dataset.drop(columns=0)\n",
    "\n",
    "#separating the target set\n",
    "target_set = np.array(dataset[1])\n",
    "dataset = dataset.drop(columns = 1)\n",
    "\n",
    "# mapping labels M = 1 and B = 0\n",
    "for index in range(len(target_set)):\n",
    "    if target_set[index] == 'M':\n",
    "        target_set[index] = 1\n",
    "    elif target_set[index] == 'B':\n",
    "        target_set[index] = 0\n",
    "\n",
    "#splitting dataset into training, validation and testing\n",
    "my_train, my_test, target_train, target_test = train_test_split(dataset, target_set,train_size = 0.8, test_size=0.2)\n",
    "my_val, my_test, target_val, target_test = train_test_split(my_test, target_test,train_size = 0.5, test_size = 0.5)\n",
    "\n",
    "# normalizing all datasets\n",
    "my_train = preprocessing.normalize(my_train)\n",
    "my_val = preprocessing.normalize(my_val)\n",
    "my_test = preprocessing.normalize(my_test)\n",
    "\n",
    "# initialize weights, bias, learning rate and number of epochs \n",
    "weights = np.zeros((30, 1))\n",
    "bias = 0\n",
    "l_rate = 0.1\n",
    "epochs = 70000\n",
    "accuracy_array = [] #used to store validation accuracy of every epoch\n",
    "cost_array = [] # stores the gradient descent for every epoch\n",
    "\n",
    "# The following 2 are required if all need to be performed together. In first round\n",
    "# iterate over the epochs, keep learning rate constant. In round two,\n",
    "# select best epoch, iterate over learning rate and select the best possible rate.\n",
    "# This above steps were followed, and thus epochs = 70k and l_rate = 0.1 was fixed.\n",
    "#l_rate_array = [0.01, 0.05, 0.1, 0.5]\n",
    "#epochs_array = [1000, 10000, 30000, 50000, 60000, 70000]\n",
    "\n",
    "def sigmoid(z):\n",
    "    # returns a value between 0 and 1 for classification\n",
    "    ans =  1 /( 1 + np.exp(-z))\n",
    "    return ans\n",
    "    \n",
    "def gradient_descent(sigma, Y, m):\n",
    "    return (-np.sum(np.multiply(np.log(sigma), Y) + np.multiply((1 - Y), np.log(1 - sigma)))/m)\n",
    "\n",
    "no_of_train = my_train.shape[0]\n",
    "my_train = my_train.T\n",
    "\n",
    "# Starting Training \n",
    "# for i in range(0, len(epochs_array)):\n",
    "#     epochs = epochs_array[i]\n",
    "for epoch in range(epochs):\n",
    "    z = np.array(np.dot(weights.T, my_train) + bias, dtype =np.float32)\n",
    "    #print(type(z))\n",
    "    sigma = sigmoid(z)\n",
    "    dz = sigma - target_train\n",
    "    cost = gradient_descent(sigma, target_train, no_of_train) # calculates cost over evry iteration\n",
    "    cost_array.append(cost)\n",
    "    dw = 1/no_of_train * np.dot(my_train, dz.T)\n",
    "    db = 1 / no_of_train * np.sum(dz)\n",
    "    # update weights and bias for every iteration\n",
    "    weights = weights - l_rate * dw\n",
    "    bias = bias - l_rate * db\n",
    "    if epoch == epochs - 1:\n",
    "        print('Done!')\n",
    "    \n",
    "plt.plot(cost_array)\n",
    "# Classify values into Class 1 = M or 0 = B\n",
    "sigma[sigma >= 0.5] = 1\n",
    "sigma[sigma < 0.5] = 0\n",
    "\n",
    "accuracy_training = (target_train == sigma).mean() * 100\n",
    "print(f\"Training accuracy for {epochs} epochs and {l_rate} learning rate is {round(accuracy_training, 2)}\")\n",
    "\n",
    "# Logistic regression for validation set\n",
    "print(\"Regression on validation set\")\n",
    "my_val = my_val.T\n",
    "z = np.array(np.dot(weights.T, my_val) + bias, dtype=np.float32)\n",
    "sigma = sigmoid(z)\n",
    "sigma = sigma.ravel() # convert to flat array\n",
    "    \n",
    "# Classify values into Class 1 = M or 0 = B\n",
    "sigma[sigma >= 0.5] = 1\n",
    "sigma[sigma < 0.5] = 0\n",
    "\n",
    "accuracy_val = (target_val == sigma).mean() * 100 # accuracy of validation set\n",
    "print(f\"Validation accuracy for {epochs} epochs and {l_rate} learning rate is {round(accuracy_val, 2)}%\")\n",
    "print(f\"{epochs} epochs Done!\")\n",
    "my_val = my_val.T # ****don't touch this.***** needed for iteration of epoch_array or l_rate_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Regression on Testing Set\n",
    "no_of_samples = my_test.shape[0]\n",
    "my_test = my_test.T\n",
    "z = np.array(np.dot(weights.T, my_test) + bias, dtype=np.float32)\n",
    "sigma = sigmoid(z)\n",
    "sigma = sigma.ravel()\n",
    "\n",
    "# Classify values into Class 1 = M or 0 = B\n",
    "sigma[sigma >= 0.5] = 1\n",
    "sigma[sigma < 0.5] = 0\n",
    "\n",
    "prediction = sigma.astype(int).copy()\n",
    "\n",
    "# Calculating Results of Logistic Regression on Testing Set.\n",
    "\n",
    "accuracy_test = (target_test == sigma).mean() * 100\n",
    "print(f\"Testing accuracy is {round(accuracy_test, 2)}%\")\n",
    "\n",
    "# forming a confusion matrix to calculate precision and recall \n",
    "predicted = np.array(prediction)\n",
    "actual = np.array(target_test.astype(int))\n",
    "conf_matrix = confusion_matrix(actual, predicted)\n",
    "print(f\"Confusion matrix = {conf_matrix}\")\n",
    "\n",
    "test_precision = np.mean(np.diag(conf_matrix) / np.sum(conf_matrix, axis = 0)) * 100\n",
    "test_recall = np.mean(np.diag(conf_matrix) / np.sum(conf_matrix, axis = 1)) * 100\n",
    "\n",
    "print(f\"Testing Precision is {round(test_precision,2)}%\")\n",
    "print(f\"Testing recall is {round(test_recall, 2)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
